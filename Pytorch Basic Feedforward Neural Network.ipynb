{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Basic Feedforward Neural Network with PyTorch\n",
    "\n",
    "Credit to https://github.com/yunjey for the original Python code found at: \n",
    "\n",
    "https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/feedforward_neural_network/main.py\n",
    "\n",
    "torch.nn is a sub-library of the torch library. When a Parameter is associated with a module as a model attribute, it gets added to the parameter list automatically and can be accessed using the 'parameters' iterator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign Model and Training Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "\n",
    "# Training\n",
    "num_epochs = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease, use an existing dataset(MNIST, handwritten number recognition), and create a training and testing `Dataset` and `DataLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "training_dataset = torchvision.datasets.MNIST('data', \n",
    "                                              train=True,\n",
    "                                              transform=transforms.ToTensor(),\n",
    "                                              download=True)\n",
    "\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=True)\n",
    "\n",
    "# Testing\n",
    "testing_dataset = torchvision.datasets.MNIST('data', \n",
    "                                             train=False,\n",
    "                                             transform=transforms.ToTensor())\n",
    "\n",
    "testing_dataloader = torch.utils.data.DataLoader(testing_dataset,\n",
    "                                                batch_size=batch_size,\n",
    "                                                shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the model\n",
    "\n",
    "`nn.Module` is the base class for all neural network modules.\n",
    "\n",
    "Your models should also subclass this class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = self.relu(output)\n",
    "        output = self.fc2(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optmizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total steps is number of training files // batch size, aka the training_dataloader size\n",
    "total_steps = len(training_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.to()`\n",
    "Performs Tensor dtype and/or device conversion. A torch.dtype and torch.device are inferred from the arguments of self.to(*args, **kwargs)\n",
    "\n",
    "Returns a Tensor with the specified dtype\n",
    "\n",
    "Each batch of `images` is packaged as a tensor in the following format: Number of Training Images, Number of Channels for a Single Image, Image Height, Image Width.\n",
    "\n",
    "Since the batch size is 64, the number of training images in a batch will be 64. As well, MNIST images are single channel meaning the number of channels in each image will be 1. The image height and width are the same: 28 pixels.\n",
    "\n",
    "Therefore, the shape of the image tensor will be (64, 1, 28, 28). The tensor can be reshaped such that the image data for is a row of values. The reshaped tensor has each row containing a training image, where the column represents the intensity value of a specific training image.\n",
    "\n",
    "It's not 100% clear to me why we use `to(device)` . It's possible the change is more obvious whe using CUDA and graphics cards for training, whereby the values may change data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for index, data in enumerate(training_dataloader):\n",
    "        images, labels = data\n",
    "        \n",
    "        print(type(images))\n",
    "        \n",
    "        # Move images to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward Pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backprop and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        break\n",
    "        if (index+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                   .format(epoch+1, num_epochs, index+1, total_steps, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n"
     ]
    }
   ],
   "source": [
    "images.reshape(-1, 28*28).to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model\n",
    "\n",
    "Don't need to compute gradients.\n",
    "\n",
    "`model(images)` outputs a list of probabilities for the classes. The length of the list is dependent on the number of test images being passed through the batch.\n",
    "\n",
    "`torch.max(output, 1)` along rank 1 because you want to get the max prediction for each batch of training images, instead of getting the max number of the entire batch. The first set of values it returns are a list of maximum values, while the second list are numbers correspnding to the values index.\n",
    "\n",
    "`labels.size(0)` provides just the number without being enclosed in a Tensor.\n",
    "\n",
    "`predicted == labels` does a conditional between two lists of numbers, returns 1 if corresponding elements in a list matchup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.82 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testing_dataloader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'basic_feedforward.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
